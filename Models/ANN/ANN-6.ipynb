{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a200ea4-593d-402e-ab3a-de65724edff3",
   "metadata": {},
   "source": [
    "# ANN with 6 strain rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbe72b-66f3-4ce3-b148-e304db0d65b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"mime\")\n",
    "import h5py\n",
    "from scipy.optimize import curve_fit\n",
    "import lmfit\n",
    "import os\n",
    "\n",
    "colors = ['#bb0000', '#00bb00', \"#0000bb\", '#bbbb00', '#bb00bb', \"#00bbbb\", '#bbbbbb', '#770000', '#007700', \"#000077\", '#777700', '#770077', \"#007777\", '#777777', '#440000', '#004400', \"#000044\", '#444400', '#440044', \"#0044444\", '#444444','#000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68263b-3f50-4165-a080-93d3bf725b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseSize = (8, 6)  # Base size of a subplot\n",
    "\n",
    "def sbPlot(n):\n",
    "    if (n == 1): return 1, 1\n",
    "    if (n <= 2): return 1, 2\n",
    "    if (n <= 4): return 2, 2\n",
    "    if (n <= 6): return 3, 2\n",
    "    if (n <= 9): return 3, 3\n",
    "    if (n <= 12): return 4, 3\n",
    "    return 0, 0\n",
    "\n",
    "def sbPlotSize(n):\n",
    "    x, y = sbPlot(n)\n",
    "    return baseSize[0] * y, baseSize[1] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c0372-b038-480d-a09e-c46b56961d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('../GleebleData.h5','r')\n",
    "allData = h5f['all'][:]\n",
    "shortData = h5f['short'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c662c3-67a2-45a6-9faa-4f6b55925d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allData.shape, shortData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e15b5e-ce7b-4a8b-8976-5ecff3badc9b",
   "metadata": {},
   "source": [
    "Remove first point of each curve, where $\\varepsilon^p=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42b9ee-29f0-48cd-92c2-d61c8088ca5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identData0 = allData[allData[:,0] != 0]\n",
    "identData = allData[allData[:,0] != 0]\n",
    "#identData = shortData[shortData[:,0]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d22c82-7124-4579-a4a6-dabf8b931a24",
   "metadata": {},
   "source": [
    "# Identification of the ANN parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d69c5-491d-4884-b00b-39a405447a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importation de TensorFlow\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras import optimizers\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f74144-44a2-4e54-9356-2033e4d7537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8d069-e7b1-40ca-8ae0-d9a5bf241530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epspl = np.unique(identData[:,0])\n",
    "depspl = np.unique(identData[:,1])\n",
    "Tl = np.unique(identData[:,2])\n",
    "nEpsp = depspl.shape[0]\n",
    "\n",
    "T0 = Tl[0]\n",
    "epsLogBase = depspl[0]\n",
    "Tm = 1460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2ea44-04f3-46f2-9773-7ecbc94c3ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identData[:,1] = np.log(identData[:,1] / epsLogBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d390050-9532-478e-856c-2da7783d7a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minEntries = identData.min(axis=0)\n",
    "maxEntries = identData.max(axis=0)\n",
    "rangeEntries = maxEntries - minEntries\n",
    "NNentries = (identData - minEntries) / rangeEntries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d93f1-2e02-4aeb-bcd3-ec349c4e94d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Max error for normalized data is : %5.4E\" %(NNentries * rangeEntries + minEntries - identData).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82b243-8392-40c3-ab0a-47666e0c9009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = sbPlotSize(nEpsp))\n",
    "plt.rc('text', usetex = True)\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "idx = 1\n",
    "for epspv, epspvv in zip(np.unique(identData[:,1]), depspl):\n",
    "    xs, ys = sbPlot(nEpsp)\n",
    "    plt.subplot(xs, ys, idx)\n",
    "    cl = 0\n",
    "    for T, TOrig in zip(np.unique(identData[:,2]), Tl):\n",
    "        # filter on T\n",
    "        data = NNentries[(identData[:,2]==T) & (identData[:,1]==epspv), :]\n",
    "        # Plot the curves\n",
    "        plt.plot(data[:,0]*rangeEntries[0]+minEntries[0], data[:,3]*rangeEntries[3]+minEntries[3], label=r'$T=' + str(TOrig) + '^{\\circ}C$', linewidth = 3)\n",
    "        cl += 1\n",
    "    plt.legend(loc = 'lower right',fancybox = True, numpoints = 1, fontsize = 10)\n",
    "    plt.xlabel(r'$Plastic\\ strain\\ \\varepsilon^{p}$', fontsize = 16)\n",
    "    plt.ylabel(r'$Von\\ Mises\\ stress\\ \\sigma$', fontsize = 16)\n",
    "    plt.title(r'$\\dot{\\varepsilon^p}=' + str(epspvv) + '\\ s^{-1}$', fontsize = 16)\n",
    "    idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b8465-0c52-4864-9b8a-8a233f280e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colEps = 0\n",
    "colEpsp = 1\n",
    "colT = 2\n",
    "colSig = 3\n",
    "NNinput = NNentries[:,colEps:colSig]\n",
    "NNoutput = NNentries[:,colSig]\n",
    "NNinput.shape, NNoutput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3372a-f911-462e-98ad-ebbe3127423b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    models = []  # The list of models to use\n",
    "    convergenceDatas = []   # To store convergence curves\n",
    "    \n",
    "    # FACT = ['tanh', 'sigmoid']\n",
    "    # COUCH = [5, 7, 9, [5,3], [7,4], [9,5]]\n",
    "    \n",
    "    FACT = ['sigmoid']\n",
    "    COUCH = [[7, 5],[9, 5],[9, 7],[13, 7],[15, 7]]\n",
    "    \n",
    "    for f in FACT:\n",
    "        for c in COUCH:\n",
    "            desc = '3'\n",
    "            model = Sequential()\n",
    "            if type(c) == list:\n",
    "                fst = True\n",
    "                for k in c:\n",
    "                    if (fst): model.add(Dense(k, input_dim = 3, activation = f))\n",
    "                    else: model.add(Dense(k, activation = f))\n",
    "                    fst = False\n",
    "                    desc += '-' + str(k)\n",
    "            else:\n",
    "                model.add(Dense(c, input_dim = 3, activation = f))\n",
    "                desc += '-' + str(c)\n",
    "            model.add(Dense(1))\n",
    "            desc += '-1-' + f\n",
    "            model._name = desc\n",
    "            models.append(model)\n",
    "            convergenceDatas.append([desc, np.array([])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f01e0-8ce7-4ff1-b482-1112d45e697c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    for model in models:\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5bbd9a-8e81-4396-9839-cfa449166467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveInternalMatrices(ANN, filename):\n",
    "    if len(ANN.layers) == 1: \n",
    "        np.savez(filename,\n",
    "                 logBase = np.array([epsLogBase]),\n",
    "                 minEntries = minEntries, \n",
    "                 maxEntries = maxEntries,\n",
    "                 w1 = ANN.layers[0].get_weights()[0].T, \n",
    "                 b1 = ANN.layers[0].get_weights()[1].reshape(len(ANN.layers[0].get_weights()[1]),1))\n",
    "    if len(ANN.layers) == 2: \n",
    "        np.savez(filename, \n",
    "                 logBase = np.array([epsLogBase]),\n",
    "                 minEntries = minEntries, \n",
    "                 maxEntries = maxEntries,\n",
    "                 w1 = ANN.layers[0].get_weights()[0].T, \n",
    "                 b1 = ANN.layers[0].get_weights()[1].reshape(len(ANN.layers[0].get_weights()[1]),1),\n",
    "                 w2 = ANN.layers[1].get_weights()[0].T, \n",
    "                 b2 = ANN.layers[1].get_weights()[1].reshape(len(ANN.layers[1].get_weights()[1]),1))\n",
    "    if len(ANN.layers) == 3: \n",
    "        np.savez(filename, \n",
    "                 logBase = np.array([epsLogBase]),\n",
    "                 minEntries = minEntries, \n",
    "                 maxEntries = maxEntries,\n",
    "                 w1 = ANN.layers[0].get_weights()[0].T, \n",
    "                 b1 = ANN.layers[0].get_weights()[1].reshape(len(ANN.layers[0].get_weights()[1]),1),\n",
    "                 w2 = ANN.layers[1].get_weights()[0].T, \n",
    "                 b2 = ANN.layers[1].get_weights()[1].reshape(len(ANN.layers[1].get_weights()[1]),1),\n",
    "                 w3 = ANN.layers[2].get_weights()[0].T, \n",
    "                 b3 = ANN.layers[2].get_weights()[1].reshape(len(ANN.layers[2].get_weights()[1]),1)) \n",
    "    if len(ANN.layers) == 4: \n",
    "        np.savez(filename, \n",
    "                 logBase = np.array([epsLogBase]),\n",
    "                 minEntries = minEntries, \n",
    "                 maxEntries = maxEntries,\n",
    "                 w1 = ANN.layers[0].get_weights()[0].T, \n",
    "                 b1 = ANN.layers[0].get_weights()[1].reshape(len(ANN.layers[0].get_weights()[1]),1),\n",
    "                 w2 = ANN.layers[1].get_weights()[0].T, \n",
    "                 b2 = ANN.layers[1].get_weights()[1].reshape(len(ANN.layers[1].get_weights()[1]),1),\n",
    "                 w3 = ANN.layers[2].get_weights()[0].T, \n",
    "                 b3 = ANN.layers[2].get_weights()[1].reshape(len(ANN.layers[2].get_weights()[1]),1),\n",
    "                 w4 = ANN.layers[3].get_weights()[0].T, \n",
    "                 b4 = ANN.layers[3].get_weights()[1].reshape(len(ANN.layers[3].get_weights()[1]),1))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971db5c0-c6ff-41b0-a757-681420f9fe38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataPath = 'ANN-6'\n",
    "\n",
    "iterationsNumber = 50 # Define the number of iteration to do\n",
    "epochNumber = 100     # Define the number of epoch for each iteration\n",
    "subSave = True\n",
    "\n",
    "if training:\n",
    "    for model, convergenceData in zip (models, convergenceDatas):\n",
    "        print(\"MODEL :\", model.name)\n",
    "        if (subSave):\n",
    "            try:\n",
    "                os.mkdir(dataPath + '/' + model.name)\n",
    "            except:\n",
    "                pass\n",
    "        for i in range(iterationsNumber):\n",
    "            history = model.fit(NNinput, NNoutput, epochs = epochNumber, verbose = 0, shuffle = True)\n",
    "            loss = history.history['loss']\n",
    "            convergenceData[1] = np.append(convergenceData[1], loss)\n",
    "            if (subSave):\n",
    "                saveInternalMatrices(model, dataPath + '/' + model.name + '/ANN-' + str(i))\n",
    "            saveInternalMatrices(model, dataPath + '/' + model.name + '.npz')\n",
    "    \n",
    "            print(\"Iteration :\", i + 1, \"/\", iterationsNumber, '-> %8.6E' % loss[-1], \"  \", end = '\\r')\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0b5b4-989b-4681-af34-f7c2ad04f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    for model in models:\n",
    "        model.save(dataPath + '/' + model.name + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b0f8c-5b46-4b50-9d6b-39f71a004b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loadModels = ['3-15-7-1-sigmoid', '3-13-7-1-sigmoid', '3-7-5-1-sigmoid', '3-9-5-1-sigmoid','3-9-7-1-sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71963a-ba29-488e-80d3-f445cce11d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (training==False):\n",
    "    models = []              # The list of models to use\n",
    "    for modName in loadModels:\n",
    "        new_model = tf.keras.models.load_model(dataPath + '/' + modName + '/model')\n",
    "        models.append(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1e6b0-0e72-4d7f-bc92-27cf2beccc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    for convergenceData in convergenceDatas:\n",
    "        name = convergenceData[0]\n",
    "        convCurve = convergenceData[1]\n",
    "        np.savez(dataPath + '/CD-' + name, convCurve = convCurve)\n",
    "        print(\"Convergence data %s saved\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c820b49-b2bf-41a4-ae1f-184680820421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (training==False):\n",
    "    convergenceDatas = []   # To store convergence curves\n",
    "    for name in loadModels:\n",
    "        NN = np.load(dataPath + '/CD-' + name + '.npz')\n",
    "        cc = [name, NN['convCurve']]\n",
    "        convergenceDatas.append(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9d92a-6f67-4deb-83af-f0c3aefe3b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 9))\n",
    "plt.rc('text', usetex = True)\n",
    "cl = 0\n",
    "for convergenceData in convergenceDatas:\n",
    "    name = convergenceData[0]\n",
    "    curve = convergenceData[1]\n",
    "    shortCurve = curve[::10]\n",
    "    x = np.linspace(0, len(curve), len(shortCurve))\n",
    "    plt.plot(x, np.log10(np.sqrt(shortCurve)), label = name, color=colors[cl], linewidth = 3)\n",
    "    cl += 1\n",
    "#plt.grid()\n",
    "plt.xlabel(r'ANN training epoch', fontsize = 16)\n",
    "#plt.ylim(-5.25, -3.5)\n",
    "plt.xlim(x.min(), x.max())\n",
    "\n",
    "plt.ylabel(r'Training error : $\\log_{10}\\left(\\text{E}_\\text{RMS}\\right)$', fontsize = 16)\n",
    "plt.title(r'Global convergence of the Artificial Neural Network model', fontsize = 16)\n",
    "plt.legend(loc = 'upper right',fancybox = True, numpoints = 1, fontsize = 14)\n",
    "plt.savefig(\"Conv-ANN-6.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710514ef-8b6e-40ac-9cb3-8b6e372d5b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562a94c-b754-44bb-8e42-c353cab44217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the curves\n",
    "from matplotlib.lines import Line2D\n",
    "def create_dummy_line(**kwds):\n",
    "    return Line2D([], [], **kwds)\n",
    "\n",
    "for model in models:\n",
    "    plt.figure(figsize = sbPlotSize(nEpsp))\n",
    "    plt.rc('text', usetex = True)\n",
    "    idx = 1\n",
    "    plt.subplots_adjust(hspace = 0.3)\n",
    "    for epsp in list(depspl):\n",
    "        xs, ys = sbPlot(nEpsp)\n",
    "        plt.subplot(xs, ys, idx)\n",
    "        sbdata = shortData[shortData[:,1]==epsp]\n",
    "        cl =0\n",
    "        for temp in list(Tl):\n",
    "            sbdata1 = sbdata[sbdata[:,2]==temp]\n",
    "            plt.plot(sbdata1[:,0], sbdata1[:,3], colors[cl], marker = 's', markersize = 5, linestyle = 'none')\n",
    "            inp = np.zeros((epspl.shape[0],3))\n",
    "            inp[:,0] = (epspl - minEntries[0]) / rangeEntries[0]\n",
    "            inp[:,1] = (np.log(epsp / epsLogBase) - minEntries[1]) / rangeEntries[1]\n",
    "            inp[:,2]  = (temp - minEntries[2]) / rangeEntries[2]\n",
    "            plt.plot(epspl, model.predict(inp)*rangeEntries[3]+minEntries[3], colors[cl], linewidth = 2.5)\n",
    "            plt.rcParams['xtick.labelsize'] = 16\n",
    "            plt.rcParams['ytick.labelsize'] = 16\n",
    "            cl +=1\n",
    "        plt.xlim(0, 0.7)\n",
    "        plt.ylim(bottom=0)\n",
    "        plt.xlabel(r'strain $\\varepsilon$', fontsize = 16) # Labels the x axis\n",
    "        plt.ylabel(r'flow stress $\\sigma^y$ (MPa)', fontsize = 16) # Labels the y axis\n",
    "        plt.title(r'strain rate $\\dot{\\varepsilon} = ' + str(epsp) + '$ s$^{-1}$', fontsize = 16) # Self explicit command\n",
    "        idx += 1\n",
    "        \n",
    "    legendLines = []\n",
    "    cl = 0\n",
    "    for temp in list(Tl):\n",
    "        legendLines.append((r'$T=$' + str(int(temp)) + r'$^{\\circ}$C', {'color':colors[cl], 'linestyle':'-', 'linewidth':2.5, 'marker':'s'}))\n",
    "        cl += 1\n",
    "    \n",
    "    plt.legend([create_dummy_line(**l[1]) for l in legendLines],[l[0] for l in legendLines], \n",
    "               loc = 'upper center', fontsize = 12, ncols = 5, bbox_to_anchor = (0.0, -0.2), shadow = False)\n",
    "    \n",
    "    plt.savefig(\"CompExpANN-\"+model.name+\".svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b7dc4-aa3b-4688-ba05-71a624545c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    ARstress = (model.predict(NNinput)*rangeEntries[3]+minEntries[3]).flatten()\n",
    "    EAAR = np.sum(np.abs((identData0[:,3] - ARstress)/(identData0[:,3])))*100/ARstress.shape[0]\n",
    "    RMSE = np.sqrt(np.sum((identData0[:,3] - ARstress)**2)/ARstress.shape[0])\n",
    "    print(\"Model %s\" %(model.name))\n",
    "    print('  RMSE = %.2f' %(RMSE)+' MPa')\n",
    "    print(\"  EAAR = %.2f\" %(EAAR) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f72ad-04b2-4b64-a87e-39dc3d7f3dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    ARstress = (model.predict(NNinput)*rangeEntries[3]+minEntries[3])\n",
    "    data = np.concatenate((identData0[:,0:3],ARstress),axis=1)\n",
    "    h5f = h5py.File(dataPath+'/'+model.name+'.h5','w')\n",
    "    h5f.create_dataset('data', data = data)\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc5fab-7c72-4b12-bb2e-8587fa11cb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def np2lat(f, n, A, prec=4):\n",
    "    if (A.ndim == 1):\n",
    "        cols = 1\n",
    "    else:\n",
    "        cols = A.shape[1]\n",
    "    tabformat = '%.'+str(prec)+'f'\n",
    "    tabalign = 'r'*cols\n",
    "    f.write('\\\\begin{equation*}\\n')\n",
    "    f.write(n+' = ')\n",
    "    f.write('\\\\left[\\n')\n",
    "    f.write('\\\\begin{array}{%s}\\n' %tabalign)\n",
    "    np.savetxt(f, A, fmt=tabformat, delimiter=' & ', newline='\\\\\\\\ \\n')\n",
    "    f.write('\\\\end{array}\\\\right]\\n')\n",
    "    f.write('\\\\end{equation*}\\n')\n",
    "\n",
    "def writeLatex(filename, model, prec=4):\n",
    "    f = open(filename, 'w')\n",
    "    w1, b1 = model.layers[0].get_weights()\n",
    "    w2, b2 = model.layers[1].get_weights()\n",
    "    w3, b3 = model.layers[2].get_weights()\n",
    "    np2lat(f, '\\\\w_1',w1.T, prec)\n",
    "    np2lat(f,'\\\\overrightarrow{b}_1',b1, prec)\n",
    "    np2lat(f, '\\\\w_2^T',w2, prec)\n",
    "    np2lat(f,'\\\\overrightarrow{b}_2',b2, prec)\n",
    "    np2lat(f, '\\\\overrightarrow{w}_3',w3, prec)\n",
    "    np2lat(f,'b_3',b3, prec)\n",
    "    np2lat(f, 'logBase',np.array([epsLogBase]), prec)\n",
    "    np2lat(f, 'minEntries',minEntries, prec)\n",
    "    np2lat(f, 'maxEntries',maxEntries, prec)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce90cea-bfd8-4f54-aa9f-0c0b6212fe3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    writeLatex(model.name+'.tex',model,prec=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e4b4b-19f1-48bc-b3a3-345e894af594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
